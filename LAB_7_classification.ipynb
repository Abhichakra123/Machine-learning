{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006b2c55-f81e-4261-aebf-348d256febb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': None}\n",
      "\n",
      "Test evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      1.00      0.77        74\n",
      "         1.0       1.00      0.86      0.92       311\n",
      "\n",
      "    accuracy                           0.89       385\n",
      "   macro avg       0.81      0.93      0.85       385\n",
      "weighted avg       0.93      0.89      0.89       385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report  # <-- this was missing\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_excel(\"Final_dataset.xlsx\")\n",
    "\n",
    "# Step 2: Fill missing values with mode\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Step 3: Split into features and target\n",
    "X = df.drop(columns=[\"ID\", \"Disease_Risk\"])\n",
    "y = df[\"Disease_Risk\"]\n",
    "\n",
    "# Step 4: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Step 6: RandomizedSearchCV\n",
    "search = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Show results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"\\nTest evaluation:\\n\")\n",
    "print(classification_report(y_test, search.best_estimator_.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b9d0ca-558c-4979-94a6-e04d76013b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:39:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of different classifiers:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>0.807792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858521</td>\n",
       "      <td>0.923875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train Accuracy  Test Accuracy  Test Precision  Test Recall  \\\n",
       "0            SVM        0.787109       0.807792        0.807792     1.000000   \n",
       "1  Decision Tree        0.890625       0.885714        1.000000     0.858521   \n",
       "2  Random Forest        0.890625       0.885714        1.000000     0.858521   \n",
       "3       AdaBoost        0.890625       0.885714        1.000000     0.858521   \n",
       "4    Naive Bayes        0.890625       0.885714        1.000000     0.858521   \n",
       "5            MLP        0.890625       0.885714        1.000000     0.858521   \n",
       "6        XGBoost        0.890625       0.885714        1.000000     0.858521   \n",
       "7       CatBoost        0.890625       0.885714        1.000000     0.858521   \n",
       "\n",
       "    Test F1  \n",
       "0  0.893678  \n",
       "1  0.923875  \n",
       "2  0.923875  \n",
       "3  0.923875  \n",
       "4  0.923875  \n",
       "5  0.923875  \n",
       "6  0.923875  \n",
       "7  0.923875  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Importing classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    catboost_available = True\n",
    "except ImportError:\n",
    "    catboost_available = False\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_excel(\"Final_dataset.xlsx\")\n",
    "\n",
    "# Step 2: Fill missing values with mode (most common value)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Step 3: Split into features and target\n",
    "X = df.drop(columns=[\"ID\", \"Disease_Risk\"])\n",
    "y = df[\"Disease_Risk\"]\n",
    "\n",
    "# Step 4: Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Define models\n",
    "models = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(max_iter=500),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "if catboost_available:\n",
    "    models[\"CatBoost\"] = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# Step 6: Train each model and collect results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Collect metrics\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Test Precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"Test Recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        \"Test F1\": f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "# Step 7: Make a table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Results of different classifiers:\\n\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2285f6-43fb-48c3-b172-0ca8abf6b64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
